from __future__ import print_function
import tensorflow.keras
import pandas as pd
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import * #Sequential
from tensorflow.keras.layers import * #Dense, Dropout, Activation, Flatten
import os
from tensorflow.keras.optimizers import *
import math
import datetime
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
batch_size = 32
num_classes = 10
epochs = 10
data_augmentation = True
save_dir = os.path.join(os.getcwd(), 'saved_models')
model_name = 'densenet_trained_model.h5'
import glob
import numpy as np
from numpy.random import permutation
from tensorflow.keras.preprocessing import image

import tensorflow.keras.backend as K

def margin_loss(y_true, y_pred):
    lamb, margin = 0.5, 0.1
    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (
        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)

def get_im(path, img_rows, img_cols, color_type=1):
    # Load as grayscale
    img = image.load_img(path, target_size=(img_rows, img_cols))
    img = image.img_to_array(img)
    return img

def load_train(img_rows, img_cols, color_type=1):
    X_train = []
    y_train = []
    print('Read train images')
    for j in range(10):
        print('Load folder c{}'.format(j))
        path = os.path.join('..',  'train',
                            'c' + str(j), '*.jpg')
        print(path)
        files = glob.glob(path)
        for fl in files:
            flbase = os.path.basename(fl)
            img = get_im(fl, img_rows, img_cols, color_type)
            X_train.append(img)
            y_train.append(j)
    X_train = np.array(X_train, dtype=np.float32)
    X_train /= 255.0
    return X_train, y_train

# The data, split between train and test sets:
x_train, y_train = load_train(299,299,3)
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')

y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)
'''
perm = permutation(len(y_train))
x_train = x_train[perm]
y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)
y_train = y_train[perm]

train_len = int(x_train.shape[0]*0.98)
x_train, x_test = x_train[:train_len],x_train[train_len:]
y_train, y_test = y_train[:train_len],y_train[train_len:]
'''

from tensorflow.keras.applications.densenet import *
from tensorflow.keras.applications.xception import Xception
#model = MobileNetV2(include_top=True,classes=10,weights=None,input_shape=(32,32,3))
raw = Xception(include_top=False,weights='imagenet',pooling='avg',input_shape=(299,299,3))
new_output = Dense(10,activation='softmax')(raw.output)
model = Model(inputs=raw.input,outputs=new_output)
# initiate RMSprop optimizer
opt = tensorflow.keras.optimizers.Adam(lr=0.0002,epsilon=1e-5)

# Let's train the model using RMSprop
model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])



es = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto', baseline=None, restore_best_weights=True)

datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.15,
    height_shift_range=0.15,
    horizontal_flip=True,
    )
datagen.fit(x_train)
model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),
                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=1,
                    verbose=1,callbacks=[es])
model.fit(x_train, y_train, batch_size=batch_size,epochs=1)
# Save model and weights
if not os.path.isdir(save_dir):
    os.makedirs(save_dir)
model_path = os.path.join(save_dir, model_name)
model.save(model_path)
print('Saved trained model at %s ' % model_path)

def load_test(img_rows, img_cols, color_type,model):
    print('Read test images')
    path = os.path.join('..', 'test', '*.jpg')
    files = glob.glob(path)
    X_test = []
    X_test_id = []
    preds = []
    total = 0
    thr = math.floor(len(files)/15)
    for fl in files:
        flbase = os.path.basename(fl)
        img = get_im(fl, img_rows, img_cols, color_type)
        X_test.append(img)
        X_test_id.append(flbase)
        total += 1
        if total % thr == 0:
            print('Read {} images from {}'.format(total, len(files)))
            
            X_test = np.array(X_test, dtype=np.float32)
            X_test /= 255.0
            results = model.predict(X_test, batch_size=32, verbose=1)
            #print("model predict")
            #print(results)
            for e in results:
                preds.append(e)
            #print(preds)
            X_test = []
    #after 10 times, there are still a few images need to process
    X_test = np.array(X_test, dtype=np.float32)
    X_test /= 255.0
    results = model.predict(X_test, batch_size=batch_size, verbose=1)
    for e in results:
        preds.append(e)
    return  X_test_id,preds

def create_submission(predictions, test_id, info):
    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3',
                                                 'c4', 'c5', 'c6', 'c7',
                                                 'c8', 'c9'])
    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)
    now = datetime.datetime.now()
    if not os.path.isdir('subm'):
        os.mkdir('subm')
    suffix = info + '_' + str(now.strftime("%Y-%m-%d-%H-%M"))
    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')
    result1.to_csv(sub_file, index=False)

test_id,test_prediction = load_test(299,299,3,model)
#test_prediction = model.predict(x_test, batch_size=64, verbose=1)

info_string = 'densenet'

create_submission(test_prediction , test_id, info_string)

